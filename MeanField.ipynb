{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "from aml_utils import test_case_checker, perform_computation, show_test_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the MNIST data (http://yann.lecun.com/exdb/mnist/) is stored in a binary format, we would rather have an API handle the loading for us. \n",
    "\n",
    "Pytorch (https://pytorch.org/) is an Automatic Differentiation library that we may see and use later in the course. \n",
    "\n",
    "Torchvision (https://pytorch.org/docs/stable/torchvision/index.html?highlight=torchvision#module-torchvision) is an extension library for pytorch that can load many of the famous data sets painlessly. \n",
    "\n",
    "We already used Torchvision for downloading the MNIST data. It is stored in a numpy array file that we will load easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('../MeanField-lib/mnist.npz'):\n",
    "    npzfile = np.load('../MeanField-lib/mnist.npz')\n",
    "    train_images_raw = npzfile['train_images_raw']\n",
    "    train_labels = npzfile['train_labels']\n",
    "    eval_images_raw = npzfile['eval_images_raw']\n",
    "    eval_labels = npzfile['eval_labels']\n",
    "else:\n",
    "    import torchvision\n",
    "    download_ = not os.path.exists('../MeanField-lib/mnist')\n",
    "    data_train = torchvision.datasets.MNIST('../MeanField-lib/mnist', train=True, transform=None, target_transform=None, download=download_)\n",
    "    data_eval = torchvision.datasets.MNIST('../MeanField-lib/mnist', train=False, transform=None, target_transform=None, download=download_)\n",
    "\n",
    "    train_images_raw = data_train.data.numpy()\n",
    "    train_labels = data_train.targets.numpy()\n",
    "    eval_images_raw = data_eval.data.numpy()\n",
    "    eval_labels = data_eval.targets.numpy()\n",
    "\n",
    "    np.savez('../MeanField-lib/mnist.npz', train_images_raw=train_images_raw, train_labels=train_labels, \n",
    "             eval_images_raw=eval_images_raw, eval_labels=eval_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_flip_prob = 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `get_thresholded_and_noised` that does image thresholding and flipping pixels. More specifically, this functions should exactly apply the following two steps in order:\n",
    "\n",
    "1. **Thresholding**: First, given the input threshold argument, you must compute a thresholded image array. This array should indicate whether each element of `images_raw` is **greater than or equal to**  the `threshold` argument. We will call the result of this step the thresholded image.\n",
    "2. **Noise Application (i.e., Flipping Pixels)**: After the image was thresholded, you should use the `flip_flags` input argument and flip the pixels with a corresponding `True` entry in `flip_flags`. \n",
    "\n",
    "  * `flip_flags` mostly consists of `False` entries, which means you should not change their corresponding pixels. Instead, whenever a pixel had a `True` entry in `flip_flags`, that pixel in the thresholded image must get flipped. This way you will obtain the noised image.\n",
    "3. **Mapping Pixels to -1/+1**: You need to make sure the output image pixels are mapped to -1 and 1 values (as opposed to 0/1 or True/False).\n",
    "\n",
    "`get_thresholded_and_noised` should take the following arguments:\n",
    "\n",
    "1. `images_raw`: A numpy array. Do not assume anything about its shape, dtype or range of values. Your function should be careless about these attributes.\n",
    "2. `threshold`: A scalar value.\n",
    "3. `flip_flags`: A numpy array with the same shape as `images_raw` and `np.bool` dtype. This array indicates whether each pixel should be flipped or not.\n",
    "\n",
    "and return the following:\n",
    "\n",
    "* `mapped_noised_image`: A numpy array with the same shape as `images_raw`.  This array's entries should either be -1 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "numpy.where(condition, x, y): Return elements chosen from x or y depending on condition.  \n",
    "Parameters:  \n",
    "- condition: array_like, or bool: Where True, yield x, otherwise yield y.\n",
    "- x, y: array_like: Values from which to choose. \n",
    "      x, y and condition need to be broadcastable to some shape.\n",
    "\n",
    "Returns:  \n",
    "- out: ndarray: An array with elements from x where condition is True, and elements from y elsewhere.\n",
    "\n",
    "1. indicate whether each element of images_raw is greater than or equal to 'threshold' => thresholded image\n",
    "    1. Calculate theshed_image array using boolean array check on images_raw.\n",
    "1. if flip_flags pixel == True that pixel in the thresholded image must get flipped => noised\n",
    "    1. Using logical_not function you create a not_threshed_image array which is logical not of threshed_image.\n",
    "    1. Use numpy where function to check condition flip_flags == True and return either value from not_threshed_image or threshed_image.\n",
    "1. Output image pixels in (-1, 1)\n",
    "\n",
    "Use numpy.where and numpy.logical_not\n",
    "How to apply numpy.logical_not using the index produced in the numpy.where:\n",
    "-return a truth array.  -1 if your image is less than threshhold, +1 if your image is larger than threshhold\n",
    "\n",
    "1. get a true/false mask based off the threshhold value.\n",
    "1. use flip_flags to flip this true/false mask. Flip flags is just a matrix of true/false. just use it to index into the matrix you wish to flip values for.\n",
    "1. get mapped_noised_image by the logic: if the mask entry is True --> then use values of 1, else use values of -1.\n",
    "\n",
    "1. comparison between images_raw and threshold and save results.\n",
    "1. use np.logical_not and np where to find where flip flags is true and return result of my result of np.logical_not. result = np.logical_not(step1) result[np.where(flip_flags == True)]. noised = thresholded^flip_flags where, thresholded is the array from step 1\n",
    "1. convert boolean results to int values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def get_thresholded_and_noised(images_raw, threshold, flip_flags):\n",
    "    \n",
    "    # Beginning of Mo's code \n",
    "    \n",
    "    #1. indicate whether each element of images_raw is greater than or equal to 'threshold' => thresholded image\n",
    "        #1. Calculate theshed_image array using boolean array check on images_raw.\n",
    "    thresholded = images_raw >= threshold\n",
    "    #2 np.logical_not(x, out, where)\n",
    "    noised = thresholded\n",
    "    np.logical_not(thresholded, out=noised, where=flip_flags.astype(bool))\n",
    "    #3\n",
    "    mapped_noised_image = np.where(noised == True, 1, -1)\n",
    "    \n",
    "    # End of Mo's code\n",
    "    \n",
    "    assert (np.abs(mapped_noised_image)==1).all()\n",
    "    return mapped_noised_image.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "561c3f3dbb93a3bc4d4111685722e8bd",
     "grade": true,
     "grade_id": "cell-a93db968174effe4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abb25d0d7a23d2c2e4fe2e3f491efea4",
     "grade": false,
     "grade_id": "cell-eef41a5ea992c15e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reference and solution images are the same to a T! Well done on this test case.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Enter nothing to go to the next image\n",
      "or\n",
      "    Enter \"s\" when you are done to recieve the three images. \n",
      "        **Don't forget to do this before continuing to the next step.**\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "def test_thresh_noise(x, seed = 12345, p = noise_flip_prob, threshold = 128):        \n",
    "    np_random = np.random.RandomState(seed=seed)\n",
    "    flip_flags = (np_random.uniform(0., 1., size=x.shape) < p)\n",
    "    return get_thresholded_and_noised(x, threshold, flip_flags)\n",
    "\n",
    "(orig_image, ref_image, test_im, success_thr) = show_test_cases(test_thresh_noise, task_id='1_V')\n",
    "\n",
    "assert success_thr\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(get_thresholded_and_noised, task_id=1)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd87bb300472c4c9b310055de4f1de43",
     "grade": true,
     "grade_id": "cell-cad4a05d0f97d19d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Applying Thresholding and Noise to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    X_true_grayscale = train_images_raw[:10, :, :]\n",
    "\n",
    "    np_random = np.random.RandomState(seed=12345)\n",
    "    flip_flags = flip_flags = (np_random.uniform(0., 1., size=X_true_grayscale.shape) < noise_flip_prob)\n",
    "    initial_pi = np_random.uniform(0, 1, size=X_true_grayscale.shape) # Initial Random Pi values\n",
    "\n",
    "    X_true = get_thresholded_and_noised(X_true_grayscale, threshold=128, flip_flags=flip_flags * 0)\n",
    "    X_noised = get_thresholded_and_noised(X_true_grayscale, threshold=128, flip_flags=flip_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a funciton named `sigmoid_2x` that given a variable $X$ computes the following:\n",
    "\n",
    "$$f(X) := \\frac{\\exp(X)}{\\exp(X) + \\exp(-X)}$$\n",
    "\n",
    "The input argument is a numpy array $X$, which could have any shape. Your output array must have the same shape as $X$.\n",
    "\n",
    "**Important Note**: Theoretically, $f$ satisfies the following equations:\n",
    "\n",
    "$$\\lim_{X\\rightarrow +\\infty} f(X) = 1$$\n",
    "$$\\lim_{X\\rightarrow -\\infty} f(X) = 0$$\n",
    "\n",
    "Your implementation must also work correctly even on these extreme edge cases. In other words, you must satisfy the following tests.\n",
    "* `sigmoid_2x(np.inf)==1` \n",
    "* `sigmoid_2x(-np.inf)==0`.\n",
    "\n",
    "**Hint**: You may find `scipy.special.expit` useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide numerator and denominator of expit $f(X):=\\frac{\\exp (X)}{\\exp (X)+\\exp (-X)}$ by $\\exp(X)$ to get $\\frac{1}{1+\\exp(-2X)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def sigmoid_2x(X):\n",
    "    \n",
    "    # Beginning of Mo's code \n",
    "    output = expit(2*X)\n",
    "    # End of Mo's code\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06fd2f7b64300f5693fafb41cbf3dcb2",
     "grade": false,
     "grade_id": "cell-cbc48be6e5a8fa92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "assert sigmoid_2x(+np.inf) == 1.\n",
    "assert sigmoid_2x(-np.inf) == 0.\n",
    "assert np.array_equal(sigmoid_2x(np.array([0, 1])).round(3), np.array([0.5, 0.881]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(sigmoid_2x, task_id=2)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffb24f0aa1edc17850f9cfbb946944e2",
     "grade": true,
     "grade_id": "cell-4e87b3b9548c3052",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Applying Mean-field Approximation to Boltzman Machine's Variational Inference Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `boltzman_meanfield` function that applies the mean-field approximation to the Boltzman machine. \n",
    "\n",
    "Recalling the textbook notation, $X_i$ is the observed value of pixel $i$, and $H_i$ is the true value of pixel $i$ (before applying noise). For instance, if we have a $3 \\times 3$ image, the corresponding Boltzman machine looks like this: \n",
    "\n",
    "```\n",
    "       X_1        X_2        X_3\n",
    "      /          /          /\n",
    "     H_1 ------ H_2 ------ H_3\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      | X_4      | X_5      | X_6\n",
    "      |/         |/         |/ \n",
    "     H_4 ------ H_5 ------ H_6\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      | X_7      | X_8      | X_9\n",
    "      |/         |/         |/ \n",
    "     H_7 ------ H_8 ------ H_9\n",
    "```     \n",
    "\n",
    "Here, we a adopt a slightly simplified notation from the textbook and define $\\mathcal{N}(i)$ to be the neighbors of pixel $i$ (the pixels adjacent to pixel $i$). For instance, in the above figure, we have $\\mathcal{N}(1) = \\{2,4\\}$, $\\mathcal{N}(2) = \\{1,3,5\\}$, and $\\mathcal{N}(5) = \\{2,4,6,8\\}$.\n",
    "\n",
    "\n",
    "With this, the process in the textbook can be summarized as follows:\n",
    "\n",
    "```\n",
    "1. for iteration = 1, 2, 3, ....,\n",
    "  2. Pick a random pixel i.\n",
    "  3. Find pixel i's new parameter as\n",
    "```\n",
    "$$\\pi_i^{\\text{new}} = \\frac{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))}{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1)) + \\exp(-\\theta_{ii}^{(2)} X_i - \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))} .$$\n",
    "```\n",
    "  4. Replace the existing parameter for pixel i with the new one.\n",
    "```\n",
    "$$\\pi_i \\leftarrow \\pi_i^{\\text{new}}$$\n",
    "\n",
    "Since our computational resources are extremely vectorized, we will make the following minor algorithmic modification and ask you to implement the following instead:\n",
    "\n",
    "```\n",
    "1. for iteration = 1, 2, 3, ....,\n",
    "  2. for each pixels i:\n",
    "  3. Find pixel i's new parameter, but do not update the original parameter yet.\n",
    "```\n",
    "$$\\pi_i^{\\text{new}} = \\frac{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))}{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1)) + \\exp(-\\theta_{ii}^{(2)} X_i - \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))} .$$\n",
    "```\n",
    "  4. Once you have computed all the new parameters, update all of them at the same time:\n",
    "```\n",
    "$$\\pi \\leftarrow \\pi^{\\text{new}}$$\n",
    "\n",
    "We assume that the parameters $\\theta_{ii}^{(2)}$ have the same value for all $i$ and denote their common value by scalar `theta_X`. Moreover, we assume that the parameters $\\theta_{ij}^{(1)}$ have the same value for all $i,j$ and denote their common value by scalar `theta_pi`.\n",
    "\n",
    "The `boltzman_meanfield` function must take the following input arguments:\n",
    "1. `images`: A numpy array with the shape `(N,height,width)`, where \n",
    "    * `N` is the number of samples and could be anything,\n",
    "    * `height` is each individual image's height in pixels (i.e., number of rows in each image),\n",
    "    * and `width` is each individual image's width in pixels (i.e., number of columns in each image).\n",
    "      * Do not assume anything about `images`'s dtype or the number of samples or the `height` or the `width`.\n",
    "      * The entries of `images` are either -1 or 1.\n",
    "2. `initial_pi`: A numpy array with the same shape as `images` (i.e. `(N,height,width)`). This variable is corresponding to the initial value of $\\pi$ in the textbook analysis and above equations. Note that for each of the $N$ images, we have a different $\\pi$ variable.\n",
    "\n",
    "3. `theta_X`: A scalar with a default value of `0.5*np.log(1/noise_flip_prob-1)`. This variable represents $\\theta_{ii}^{(2)}$ in the above update equation.\n",
    "\n",
    "4. `theta_pi`: A scalar with a default value of 2. This variable represents $\\theta_{ij}^{(1)}$ in the above update equation.\n",
    "\n",
    "5. `iterations`: A scalar with a default value of 100. This variable denotes the number of update iterations to perform.\n",
    "\n",
    "The `boltzman_meanfield` function must return the final $\\pi$ variable as a numpy array called `pi`, and should contain values that are between 0 and 1. \n",
    "\n",
    "**Hint**: You may find the `sigmoid_2x` function, that you implemented earlier, useful.\n",
    "\n",
    "**Hint**: If you want to find the summation of neighboring elements for all of a 2-dimensional matrix, there is an easy and efficient way using matrix operations. You can initialize a zero matrix, and then add four shifted versions (i.e., left-, right-, up-, and down-shifted versions) of the original matrix to it. You will have to be careful in the assignment and selection indices, since you will have to drop one row/column for each shifted version of the matrix.\n",
    "\n",
    "  * **Important Note**: Do **not** use `np.roll` if you're taking this approach.\n",
    "  \n",
    "**Important Note**: When evaluating the neighborhood sum experssions (i.e., terms with $\\sum_{j\\in \\mathcal{N}(i)}$), make sure that you do not inadvertently include a \"ghost\" pixel in $\\mathcal{N}(i)$. For instance, make sure you're only using `H_5`, `H_7`, `H_9`, and `X_8`  when computing an update for `H_8`. That is, only left-, right-, and down-shifted pixels should be contributing to `H_8`'s neighourhood sums. If you mistakenly add an up-shifted pixel to `H_8`'s neighourhood sums (whether it's a copy of `H_8` or a no-ink/zero pixel), you are effectively imposing an extra neighborhood edge between `H_8` and a \"ghost\" pixel below it; notice that our boltzman machine doesn't have a neighborhood edge between `H_8` and anything below it, therefore, neither `H_8` nor an extra non-inky pixel should be participating in `H_8`'s neighborhood sums and update.\n",
    "  * Missing this point can cause an initial mismatche in the edge pixel updates, which will be disseminated through iterative updates to other pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "1. Create a separate function which uses matrix operations to calculate sum of neighboring elements of pi  \n",
    "1. For each iteration:  \n",
    "- For each pi  \n",
    "  - get neighboring value sum array using step 1 function  \n",
    "  - Calculate the term for updating parameters:$\\theta_{i i}^{(2)} X_{i}+\\sum_{j \\in \\mathcal{N}(i)} \\theta_{i j}^{(1)}\\left(2 \\pi_{j}-1\\right)$\n",
    "3. Pass above term through sigmoid_2x function to get updated value for $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def boltzman_meanfield(images, initial_pi, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=2, iterations=100):\n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll add a dummy dimension to be consistent\n",
    "        X = images.reshape(1,*images.shape)\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        X = images\n",
    "    \n",
    "    pi = initial_pi\n",
    "    \n",
    "    # Beginning of Mo's code \n",
    "    \n",
    "    #1 Create a separate function which uses matrix operations to calculate sum of neighboring elements of pi\n",
    "    def shift(pi, right, up):\n",
    "        e = np.empty_like(pi)\n",
    "        if right >= 0:\n",
    "            e[:, :right, :] = 0\n",
    "            e[:, right:, :] = pi[:, :-right, :]\n",
    "        else:\n",
    "            e[:, right:, :] = 0\n",
    "            e[:, :right, :] = pi[:, -right:, :]\n",
    "        if up >= 0:\n",
    "            e[:, :, :up] = 0\n",
    "            e[:, :, up:] = pi[:, :, :-up]\n",
    "        else:\n",
    "            e[:, :, up:] = 0\n",
    "            e[:, :, :up] = pi[:, :, -up:]\n",
    "        return e\n",
    " \n",
    "    def SumNi(pi):\n",
    "        #Ni = shift(pi, 1, 0) + shift(pi, -1, 0) + shift(pi, 0, 1) + shift(pi, 0, -1) #original\n",
    "        #left[left!=0]=2*left[left!=0]-1 ##from campuswire???\n",
    "        #do I multiply all pi here by theta_pi?\n",
    "        r = shift(pi, 1, 0)[shift(pi, 1, 0) !=0]   = 2 * shift(pi, 1, 0)[shift(pi, 1, 0) != 0] - 1 \n",
    "        l = shift(pi, -1, 0)[shift(pi, -1, 0) !=0] = 2 * shift(pi, -1, 0)[shift(pi, -1, 0) != 0] - 1 \n",
    "        d = shift(pi, 0, -1)[shift(pi, 0, -1) !=0] = 2 * shift(pi, 0, -1)[shift(pi, 0, -1) != 0] - 1 \n",
    "        u = shift(pi, 0, 1)[shift(pi, 0, 1) !=0]   = 2 * shift(pi, 0, 1)[shift(pi, 0, 1) != 0] - 1\n",
    "        Ni = r + l + d + u\n",
    "        return Ni\n",
    "\n",
    "    #do I replace pi with theta_pi * (2 * pi - 1)\n",
    "    for i in range(iterations):\n",
    "        #2   - get neighboring value sum array using step 1 function  \n",
    "        #    - Calculate the term for updating parameters\n",
    "        #cmn_term = theta_X * X + SumNi(pi) * theta_pi * (2 * pi - 1)\n",
    "        \n",
    "        cmn_term = theta_X * X + SumNi(theta_pi * (2 * pi - 1))\n",
    "\n",
    "        #3 Pass above term through sigmoid_2x function to get updated value for pi\n",
    "        pi = sigmoid_2x(cmn_term)\n",
    "    \n",
    "    # End of Mo's code\n",
    "        \n",
    "    return pi.reshape(*images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c4d1e6bb5955c72b4b6bb6f531ca4e7",
     "grade": true,
     "grade_id": "cell-6291d0a80ccca660",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad443dcff24418f1516c398a81fe0d19",
     "grade": false,
     "grade_id": "cell-4b0e9d79c287e537",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,28,0) into shape (100,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     initial_pi \u001b[38;5;241m=\u001b[39m np_random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m boltzman_meanfield(x, initial_pi, theta_X\u001b[38;5;241m=\u001b[39mtheta_X, \n\u001b[1;32m      6\u001b[0m                               theta_pi\u001b[38;5;241m=\u001b[39mtheta_pi, iterations\u001b[38;5;241m=\u001b[39miterations)\n\u001b[0;32m----> 8\u001b[0m (orig_image, ref_image, test_im, success_is_row_inky) \u001b[38;5;241m=\u001b[39m \u001b[43mshow_test_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_boltzman\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3_V\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m success_is_row_inky\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "File \u001b[0;32m~/work/release/MeanField-lib/aml_utils.py:451\u001b[0m, in \u001b[0;36mshow_test_cases\u001b[0;34m(test_func, task_id)\u001b[0m\n\u001b[1;32m    449\u001b[0m orig_images \u001b[38;5;241m=\u001b[39m npz_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_images\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    450\u001b[0m ref_images \u001b[38;5;241m=\u001b[39m npz_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref_images\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 451\u001b[0m test_images \u001b[38;5;241m=\u001b[39m \u001b[43mtest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m rtol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-05\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanfield\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m this_dir\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(task_id)):\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtest_boltzman\u001b[0;34m(x, seed, theta_X, theta_pi, iterations)\u001b[0m\n\u001b[1;32m      3\u001b[0m np_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m      4\u001b[0m initial_pi \u001b[38;5;241m=\u001b[39m np_random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mboltzman_meanfield\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtheta_pi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mboltzman_meanfield\u001b[0;34m(images, initial_pi, theta_X, theta_pi, iterations)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#do I replace pi with theta_pi * (2 * pi - 1)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#2   - get neighboring value sum array using step 1 function  \u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#    - Calculate the term for updating parameters\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m#cmn_term = theta_X * X + SumNi(pi) * theta_pi * (2 * pi - 1)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     cmn_term \u001b[38;5;241m=\u001b[39m theta_X \u001b[38;5;241m*\u001b[39m X \u001b[38;5;241m+\u001b[39m \u001b[43mSumNi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_pi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m#3 Pass above term through sigmoid_2x function to get updated value for pi\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     pi \u001b[38;5;241m=\u001b[39m sigmoid_2x(cmn_term)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mboltzman_meanfield.<locals>.SumNi\u001b[0;34m(pi)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSumNi\u001b[39m(pi):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#Ni = shift(pi, 1, 0) + shift(pi, -1, 0) + shift(pi, 0, 1) + shift(pi, 0, -1) #original\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#left[left!=0]=2*left[left!=0]-1 ##from campuswire???\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#do I multiply all pi here by theta_pi?\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     r \u001b[38;5;241m=\u001b[39m shift(pi, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)[shift(pi, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m]   \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[shift(pi, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     37\u001b[0m     l \u001b[38;5;241m=\u001b[39m shift(pi, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)[shift(pi, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m shift(pi, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)[shift(pi, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     38\u001b[0m     d \u001b[38;5;241m=\u001b[39m shift(pi, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[shift(pi, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m shift(pi, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[shift(pi, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mboltzman_meanfield.<locals>.shift\u001b[0;34m(pi, right, up)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m up \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     23\u001b[0m     e[:, :, :up] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     e[:, :, up:] \u001b[38;5;241m=\u001b[39m pi[:, :, :\u001b[38;5;241m-\u001b[39mup]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     e[:, :, up:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100,28,0) into shape (100,28,28)"
     ]
    }
   ],
   "source": [
    "# Performing sanity checks on your implementation\n",
    "def test_boltzman(x, seed = 12345, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=2, iterations=100):        \n",
    "    np_random = np.random.RandomState(seed=seed)\n",
    "    initial_pi = np_random.uniform(0,1, size=x.shape)\n",
    "    return boltzman_meanfield(x, initial_pi, theta_X=theta_X, \n",
    "                              theta_pi=theta_pi, iterations=iterations)\n",
    "    \n",
    "(orig_image, ref_image, test_im, success_is_row_inky) = show_test_cases(test_boltzman, task_id='3_V')\n",
    "\n",
    "assert success_is_row_inky\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(boltzman_meanfield, task_id=3)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9113db2afe6beff274efe3be511fcf17",
     "grade": true,
     "grade_id": "cell-e7b59624d7ab9ec3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tuning the Boltzman Machine's Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the `boltzman_meanfield` function that you implemented above, here see the effect of changing hyper parameters `theta_X` and `theta_pi` which were defined in Task 3. \n",
    "\n",
    "- We set `theta_X` to be `0.5*np.log(1/noise_flip_prob-1)` where `noise_flip_prob` was the probability of flipping each pixel. Try to think why this is a reasonable choice. (This is also related to one of the questions in the follow-up quiz).\n",
    "- We try different values for `theta_pi`. \n",
    "\n",
    "For each value of `theta_pi`, we the apply the denoising and compare the denoised images to the original ones. We adopt several statistical measures to compare original and denoised images and to finally decide which value of `theta_pi` is better. Remember that during the noising process, we chose some pixels and decide to flip them, and during the denoising process we essentially try to detect such pixels. Let `P` be the total number of pixels that we flip during the noise adding process, and `N` be the total number of pixels that we do not flip during the noise adding process. We can define:\n",
    "\n",
    "- True Positive (`TP`). Defined to be the total number of pixels that are flipped during the noise adding process, and we successfully detect them during the denoising process. \n",
    "- True Positive Rate (`TPR`). Other names: sensitivity, recall. Defined to be the ratio `TP / P`.\n",
    "- False Positive (`FP`). Defined to be the number of pixels that were detected as being noisy during the denosing process, but were not really noisy. \n",
    "- False Positive Rate (`FPR`). Other name: fall-out. Defined to be the ratio `FP/N`.\n",
    "- Positive Predictive Value (`PPV`). Other name: precision. Defined to be the ratio `TP / (TP + FP)`.\n",
    "- `F1` score. Defined to be the harmonic mean of precision (`PPV`) and recall (`TPR`), or equivalently `2 TP / (2 TP + FP + FN)`. \n",
    "\n",
    "Since we fix `theta_X` in this section and evaluate different values of `theta_pi`, in the plots, `theta` refers to `theta_pi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    P = true_labels.sum()\n",
    "    if P==0:\n",
    "        TPR = 1.\n",
    "    else:\n",
    "        TPR = TP / P\n",
    "    \n",
    "    return TPR\n",
    "\n",
    "def get_fpr(preds, true_labels):\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    N = (1-true_labels).sum()\n",
    "    if N==0:\n",
    "        FPR=1\n",
    "    else:\n",
    "        FPR = FP / N\n",
    "    return FPR\n",
    "\n",
    "def get_ppv(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    if (TP + FP) == 0:\n",
    "        PPV = 1\n",
    "    else:\n",
    "        PPV = TP / (TP + FP)\n",
    "    return PPV\n",
    "\n",
    "def get_f1(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    FN = ((1-preds) * (preds != true_labels)).sum()\n",
    "    if (2 * TP + FP + FN) == 0:\n",
    "        F1 = 1\n",
    "    else:\n",
    "        F1 = (2 * TP) / (2 * TP + FP + FN)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    all_theta = np.arange(0, 10, 0.2).tolist() + np.arange(10, 100, 5).tolist()\n",
    "\n",
    "    tpr_list, fpr_list, ppv_list, f1_list = [], [], [], []\n",
    "\n",
    "    for theta in all_theta:\n",
    "        meanfield_pi = boltzman_meanfield(X_noised, initial_pi, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=theta, iterations=100)\n",
    "        X_denoised = 2 * (meanfield_pi > 0.5) - 1\n",
    "\n",
    "        predicted_noise_pixels = (X_denoised != X_noised)\n",
    "        tpr = get_tpr(predicted_noise_pixels, flip_flags)\n",
    "        fpr = get_fpr(predicted_noise_pixels, flip_flags)\n",
    "        ppv = get_ppv(predicted_noise_pixels, flip_flags)\n",
    "        f1 = get_f1(predicted_noise_pixels, flip_flags)\n",
    "\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        ppv_list.append(ppv)\n",
    "        f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4), dpi=90)\n",
    "\n",
    "    ax=axes[0]\n",
    "    ax.plot(all_theta, tpr_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('True Positive Rate Vs. Theta')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax=axes[1]\n",
    "    ax.plot(all_theta, fpr_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('False Positive Rate')\n",
    "    ax.set_title('False Positive Rate Vs. Theta')\n",
    "    ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,3), dpi=90)\n",
    "\n",
    "    ax=axes[0]\n",
    "    ax.plot(fpr_list, tpr_list)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.plot(np.arange(-0.05, 1.05, 0.01), np.arange(-0.05, 1.05, 0.01), ls='--', c='black')\n",
    "\n",
    "    ax=axes[1]\n",
    "    ax.plot(all_theta, f1_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('F1-statistic')\n",
    "    ax.set_title('F1-score Vs. Theta')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax=axes[2]\n",
    "    ax.plot(tpr_list, ppv_list)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision Vs. Recall')\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.plot(np.arange(-0.05, 1.05, 0.01), 1-np.arange(-0.05, 1.05, 0.01), ls='--', c='black')\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    best_theta = all_theta[np.argmax(f1_list)]\n",
    "    print(f'Best theta w.r.t. the F-score is {best_theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the tuned hyper-parameters, and verify whether it visually improved the Boltzman machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcf7222a9bdbdad835c3619b26951d2a",
     "grade": true,
     "grade_id": "cell-00c232dc99ca3fdd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is left empty as a seperator. You can leave this cell as it is, and you should not delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a81e48e3a26b11375f6233eb7c85b8",
     "grade": false,
     "grade_id": "cell-0bc15b375e9d1ec4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    def test_boltzman(x, seed = 12345, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=best_theta, iterations=100):        \n",
    "        np_random = np.random.RandomState(seed=seed)\n",
    "        initial_pi = np_random.uniform(0,1, size=x.shape)\n",
    "        return boltzman_meanfield(x, initial_pi, theta_X=theta_X, \n",
    "                                  theta_pi=theta_pi, iterations=iterations) >  0.5\n",
    "\n",
    "    (orig_image, ref_image, test_im, success_is_row_inky) = show_test_cases(test_boltzman, task_id='4_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/MeanField/MeanField.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
